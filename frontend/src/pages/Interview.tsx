import { useState, useRef, useEffect } from "react";
import { useNavigate } from "react-router-dom";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card";
import { Progress } from "@/components/ui/progress";
import { Badge } from "@/components/ui/badge";
import { 
  Mic, MicOff, Video, VideoOff, Play, Pause, 
  SkipForward, Settings, HelpCircle, Clock 
} from "lucide-react";
import { useToast } from "@/hooks/use-toast";


const BASE_URL = import.meta.env.VITE_API_BASE_URL;

const Interview = () => {
  const navigate = useNavigate();
  const { toast } = useToast();
  const videoRef = useRef<HTMLVideoElement>(null);

  const [currentQuestion, setCurrentQuestion] = useState(0);
  const [isRecording, setIsRecording] = useState(false);
  const [isVideoOn, setIsVideoOn] = useState(true);
  const [isMicOn, setIsMicOn] = useState(true);
  const [timeRemaining, setTimeRemaining] = useState(180);
  const [transcription, setTranscription] = useState("");
  const [isInterviewStarted, setIsInterviewStarted] = useState(false);

  const wsRef = useRef<WebSocket | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);

  const questions = [
    "ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”. ë³¸ì¸ì˜ ê°•ì ê³¼ ê²½í—˜ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.",
    "ì§€ì›í•˜ì‹  ì§ë¬´ì— ëŒ€í•œ ì´í•´ë„ì™€ ê´€ë ¨ ê²½í—˜ì— ëŒ€í•´ ë§ì”€í•´ì£¼ì„¸ìš”.",
    "ê°€ì¥ ë„ì „ì ì´ì—ˆë˜ í”„ë¡œì íŠ¸ ê²½í—˜ê³¼ ê·¸ë•Œ ì–´ë–»ê²Œ ë¬¸ì œë¥¼ í•´ê²°í–ˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
    "íŒ€ì›Œí¬ê°€ ì¤‘ìš”í•œ ìƒí™©ì—ì„œì˜ ê²½í—˜ê³¼ ë³¸ì¸ì˜ ì—­í• ì— ëŒ€í•´ ë§ì”€í•´ì£¼ì„¸ìš”.",
    "5ë…„ í›„ ë³¸ì¸ì˜ ëª¨ìŠµê³¼ ì»¤ë¦¬ì–´ ëª©í‘œì— ëŒ€í•´ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”."
  ];

  useEffect(() => {
    let interval: NodeJS.Timeout;
    if (isRecording && timeRemaining > 0) {
      interval = setInterval(() => {
        setTimeRemaining((prev) => prev - 1);
      }, 1000);
    } else if (timeRemaining === 0) {
      handleNextQuestion();
    }
    return () => clearInterval(interval);
  }, [isRecording, timeRemaining]);

  useEffect(() => {
    const setupCamera = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        if (videoRef.current) videoRef.current.srcObject = stream;
      } catch (error) {
        console.error("Camera setup failed:", error);
        toast({
          title: "ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨",
          description: "ì¹´ë©”ë¼ì™€ ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
          variant: "destructive"
        });
      }
    };
    if (isVideoOn) setupCamera();
  }, [isVideoOn, toast]);

  const startSpeechRecognition = async () => {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaStreamRef.current = stream;

        const audioContext = new AudioContext();
        await audioContext.audioWorklet.addModule("/audio-processor.js");

        const source = audioContext.createMediaStreamSource(stream);
        const workletNode = new AudioWorkletNode(audioContext, "audio-processor");

        wsRef.current = new WebSocket("ws://localhost:8765");

        wsRef.current.onopen = () => {
            console.log("ğŸ™ï¸ STT WebSocket ì—°ê²°ë¨");

            workletNode.port.onmessage = (event) => {
                const float32Data = new Float32Array(event.data);
                if (wsRef.current?.readyState === WebSocket.OPEN) {
                    wsRef.current.send(float32Data.buffer);
                }
            };

            source.connect(workletNode).connect(audioContext.destination);
        };

        wsRef.current.onmessage = (event) => {
            const text = event.data;
            if (text) {
                setTranscription((prev) => prev + " " + text);
            }
        };

        wsRef.current.onerror = (err) => {
            console.error("STT WebSocket ì—ëŸ¬:", err);
        };

        wsRef.current.onclose = () => {
            console.log("ğŸ”Œ STT ì—°ê²° ì¢…ë£Œ");
        };

    } catch (err) {
        console.error("ğŸ¤ ìŒì„± ì¸ì‹ ì‹¤íŒ¨:", err);
        toast({
            title: "ìŒì„± ì¸ì‹ ì‹¤íŒ¨",
            description: "ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.",
            variant: "destructive"
        });
    }
};


  const stopSpeechRecognition = () => {
    processorRef.current?.disconnect();
    mediaStreamRef.current?.getTracks().forEach((track) => track.stop());
    wsRef.current?.close();
    processorRef.current = null;
    mediaStreamRef.current = null;
    wsRef.current = null;
  };

  const startInterview = async () => {
    setIsInterviewStarted(true);
    setIsRecording(true);
    setTranscription("");
    startSpeechRecognition();

    // ë©´ì ‘ ì‹œì‘ ì•Œë¦¼ ì „ì†¡
    try {
      await fetch(`${BASE_URL}/api/interview/start`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          timestamp: new Date().toISOString()
        })
      });
      console.log("âœ… ë©´ì ‘ ì‹œì‘ ìš”ì²­ ì „ì†¡ ì™„ë£Œ");
    } catch (err) {
      console.error("âŒ ë©´ì ‘ ì‹œì‘ ìš”ì²­ ì‹¤íŒ¨:", err);
      toast({
        title: "ë©´ì ‘ ì‹œì‘ ì‹¤íŒ¨",
        description: "ì„œë²„ì— ë©´ì ‘ ì‹œì‘ ìš”ì²­ì„ ì „ì†¡í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
        variant: "destructive"
      });
    }

    toast({
      title: "ë©´ì ‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤",
      description: "í¸ì•ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì–¸ì œë“  ì¼ì‹œì •ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    });
  };


  const toggleRecording = () => {
    const nextState = !isRecording;
    setIsRecording(nextState);
    nextState ? startSpeechRecognition() : stopSpeechRecognition();
    toast({
      title: nextState ? "ë©´ì ‘ ì¬ì‹œì‘" : "ë©´ì ‘ ì¼ì‹œì •ì§€",
      description: nextState ? "ë©´ì ‘ì´ ì¬ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤." : "ë©´ì ‘ì´ ì¼ì‹œì •ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."
    });
  };

  const handleNextQuestion = async () => {
    const questionText = questions[currentQuestion];
    const answerText = transcription.trim();

    try {
      await fetch(`${BASE_URL}/api/interview/response`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          question: questionText,
          answer: answerText
        })
      });
      console.log(`âœ… ì§ˆë¬¸ ì „ì†¡ ì™„ë£Œ: ${questionText}`);
    } catch (err) {
      console.error("âŒ ì‘ë‹µ ì „ì†¡ ì‹¤íŒ¨:", err);
      toast({
        title: "ì „ì†¡ ì‹¤íŒ¨",
        description: "ì‘ë‹µ ë°ì´í„°ë¥¼ ì„œë²„ë¡œ ì „ì†¡í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
        variant: "destructive"
      });
    }

    if (currentQuestion < questions.length - 1) {
      setCurrentQuestion(currentQuestion + 1);
      setTimeRemaining(180);
      setTranscription("");
      toast({
        title: "ë‹¤ìŒ ì§ˆë¬¸",
        description: `ì§ˆë¬¸ ${currentQuestion + 2}ë²ˆìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.`
      });
    } else {
      toast({
        title: "ë©´ì ‘ ì™„ë£Œ!",
        description: "ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤. ê²°ê³¼ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."
      });
      stopSpeechRecognition();
      setTimeout(() => navigate("/results/1"), 2000);
    }
  };


  const toggleVideo = () => setIsVideoOn(!isVideoOn);
  const toggleMic = () => setIsMicOn(!isMicOn);
  const formatTime = (seconds: number) => `${Math.floor(seconds / 60)}:${(seconds % 60).toString().padStart(2, '0')}`;

  return (
    <div className="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-8">
      {/* Header */}
      <div className="mb-6">
        <div className="flex items-center justify-between">
          <div>
            <h1 className="text-2xl font-bold text-slate-900">AI ë©´ì ‘ ì§„í–‰</h1>
            <p className="text-slate-600">ì‹¤ì œ ë©´ì ‘ì²˜ëŸ¼ ì§„í–‰ë©ë‹ˆë‹¤. ì¹¨ì°©í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.</p>
          </div>
          <div className="flex items-center gap-4">
            <Badge variant="outline" className="text-sm">
              ì§ˆë¬¸ {currentQuestion + 1} / {questions.length}
            </Badge>
            {isInterviewStarted && (
              <div className="flex items-center gap-2 text-lg font-mono">
                <Clock className="h-5 w-5" />
                {formatTime(timeRemaining)}
              </div>
            )}
          </div>
        </div>
        <Progress value={((currentQuestion + 1) / questions.length) * 100} className="mt-4 h-2" />
      </div>

      {/* Current Question */}
      <div className="mb-8">
        <Card className="border-2 border-blue-200 bg-gradient-to-r from-blue-50 to-indigo-50">
          <CardHeader className="pb-4">
            <CardTitle className="flex items-center text-blue-700">
              <HelpCircle className="mr-3 h-6 w-6" />
              ì§ˆë¬¸ {currentQuestion + 1}
            </CardTitle>
          </CardHeader>
          <CardContent>
            <div className="text-center">
              <p className="text-2xl md:text-3xl lg:text-4xl font-semibold leading-relaxed text-slate-800 mb-6">
                {questions[currentQuestion]}
              </p>
              <div className="p-4 bg-blue-100 rounded-lg border border-blue-200">
                <p className="text-base text-blue-800">
                  ğŸ’¡ <strong>ë‹µë³€ íŒ:</strong> êµ¬ì²´ì ì¸ ê²½í—˜ê³¼ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì—¬ ë‹µë³€í•˜ë©´ ë” ì¢‹ì€ í‰ê°€ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                </p>
              </div>
            </div>
          </CardContent>
        </Card>
      </div>

      <div className="grid lg:grid-cols-3 gap-8">
        {/* Video and Controls */}
        <div className="lg:col-span-2">
          <Card>
            <CardHeader>
              <CardTitle className="flex items-center justify-between">
                <span>ë©´ì ‘ í™”ë©´</span>
                <div className="flex gap-2">
                  <Button variant="outline" size="sm" onClick={toggleVideo} className={isVideoOn ? "" : "bg-red-50 border-red-200"}>
                    {isVideoOn ? <Video className="h-4 w-4" /> : <VideoOff className="h-4 w-4" />}
                  </Button>
                  <Button variant="outline" size="sm" onClick={toggleMic} className={isMicOn ? "" : "bg-red-50 border-red-200"}>
                    {isMicOn ? <Mic className="h-4 w-4" /> : <MicOff className="h-4 w-4" />}
                  </Button>
                  <Button variant="outline" size="sm">
                    <Settings className="h-4 w-4" />
                  </Button>
                </div>
              </CardTitle>
            </CardHeader>
            <CardContent>
              <div className="relative bg-slate-900 rounded-lg overflow-hidden">
                <video ref={videoRef} autoPlay muted className="w-full h-64 md:h-80 object-cover" style={{ display: isVideoOn ? 'block' : 'none' }} />
                {!isVideoOn && (
                  <div className="w-full h-64 md:h-80 flex items-center justify-center text-white">
                    <div className="text-center">
                      <VideoOff className="h-12 w-12 mx-auto mb-2 opacity-50" />
                      <p className="text-sm opacity-75">ì¹´ë©”ë¼ê°€ êº¼ì ¸ìˆìŠµë‹ˆë‹¤</p>
                    </div>
                  </div>
                )}
                {isRecording && (
                  <div className="absolute top-4 left-4 flex items-center gap-2 bg-red-600 text-white px-3 py-1 rounded-full text-sm">
                    <div className="w-2 h-2 bg-white rounded-full animate-pulse" />
                    ë…¹í™” ì¤‘
                  </div>
                )}
                <div className="absolute top-4 right-4 bg-black/50 text-white px-3 py-1 rounded-full text-sm">
                  AI ë¶„ì„ ì¤‘...
                </div>
              </div>

              <div className="flex justify-center gap-4 mt-6">
                {!isInterviewStarted ? (
                  <Button onClick={startInterview} size="lg" className="bg-blue-600 hover:bg-blue-700">
                    <Play className="mr-2 h-5 w-5" />
                    ë©´ì ‘ ì‹œì‘
                  </Button>
                ) : (
                  <>
                    <Button onClick={toggleRecording} variant={isRecording ? "destructive" : "default"} size="lg">
                      {isRecording ? (<><Pause className="mr-2 h-5 w-5" />ì¼ì‹œì •ì§€</>) : (<><Play className="mr-2 h-5 w-5" />ì¬ì‹œì‘</>)}
                    </Button>
                    <Button onClick={handleNextQuestion} variant="outline" size="lg" disabled={currentQuestion >= questions.length - 1}>
                      <SkipForward className="mr-2 h-5 w-5" />
                      ë‹¤ìŒ ì§ˆë¬¸
                    </Button>
                  </>
                )}
              </div>
            </CardContent>
          </Card>
        </div>

        {/* Transcription */}
        <div>
          <Card>
            <CardHeader>
              <CardTitle>ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹</CardTitle>
            </CardHeader>
            <CardContent>
              <div className="min-h-32 p-4 bg-slate-50 rounded-lg border">
                {transcription ? (
                  <p className="text-slate-700">{transcription}</p>
                ) : (
                  <p className="text-slate-400 italic">
                    {isRecording ? "ìŒì„±ì„ ì¸ì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤..." : "ìŒì„± ì¸ì‹ì´ ì¼ì‹œì •ì§€ë˜ì—ˆìŠµë‹ˆë‹¤"}
                  </p>
                )}
              </div>
              <div className="grid grid-cols-2 gap-4 mt-4">
                <div className="text-center p-2 bg-green-50 rounded-lg">
                  <div className="text-sm text-green-600">ë§í•˜ê¸° ì†ë„</div>
                  <div className="text-lg font-bold text-green-700">ì ì ˆ</div>
                </div>
                <div className="text-center p-2 bg-blue-50 rounded-lg">
                  <div className="text-sm text-blue-600">ì‹œì„  ì²˜ë¦¬</div>
                  <div className="text-lg font-bold text-blue-700">ì–‘í˜¸</div>
                </div>
              </div>
            </CardContent>
          </Card>
        </div>
      </div>
    </div>
  );
};

export default Interview;


